#from pylab import *
#%pylab qt4

import copy
import os
from subprocess import call

import numpy as np
import sklearn
import sklearn.linear_model
from scipy import misc  # for imresize, etc

import h5py

print("Converting...")
cifar_python_directory = os.path.abspath("cifar-100-python")
cifar_caffe_directory = os.path.abspath('cifar_100_caffe_hdf5/')
if not os.path.exists(cifar_caffe_directory):
    def unpickle(file):
        import cPickle
        fo = open(file, 'rb')
        dict = cPickle.load(fo)
        fo.close()
        return dict
    def shuffle_data(data, labels):
        data, _, labels, _ = sklearn.cross_validation.train_test_split(
            data, labels, test_size=0.0, random_state=42
        )
        return data, labels
    def load_data(train_file):
        data = []
        labels = []
        d = unpickle(
            os.path.join(cifar_python_directory, train_file)
        )
        data = d['data']
        coarse_labels = d['coarse_labels']
        fine_labels = d['fine_labels']
        length = len(d['fine_labels'])
    
        data, labels = shuffle_data(
            data,
            np.array(zip(coarse_labels, fine_labels))
        )
        coarse_labels, fine_labels = zip(*labels.tolist())
    
        return (
            scale(data.reshape(length, 3, 32, 32), length),
            np.array(coarse_labels),
            np.array(fine_labels)
        )
 
    def scale(data, length):
        d = numpy.zeros(shape=(length,3,48,48))
        for i in range(length):
            img = data[i].transpose(1,2,0) # dim 32x32x3
            #figure(1)
            #imshow(img) # dim 32x32x3
            scimg = misc.imresize(img, (48,48), interp='bicubic') / 256.0  # scimg dim 48x48x3
            d[i] = scimg.transpose(2,0,1) # dim 3x48x48
            #figure(2)
            #imshow(d[i].transpose(1,2,0)) # dim 48x48x3
            #a = raw_input("Next?")
        return d

    X, y_c, y_f = load_data("train")

    Xt, yt_c, yt_f = load_data("test")
    
    print("INFO: Each dataset's element should be of shape 3x48x48 (scaled up from 3x32x32):")
    print('"print(X.shape)" --> "{}"\n'.format(X.shape))
    print("Data is loaded; now converting to HDF5 DB.")
    
    os.makedirs(cifar_caffe_directory)
    train_filename = os.path.join(cifar_caffe_directory, 'train.h5')
    test_filename = os.path.join(cifar_caffe_directory, 'test.h5')
    
    comp_kwargs = {'compression': 'gzip', 'compression_opts': 1}
    # Train
    with h5py.File(train_filename, 'w') as f:
        f.create_dataset('data', data=X, **comp_kwargs)
        f.create_dataset('label_coarse', data=y_c.astype(np.int_), **comp_kwargs)
        f.create_dataset('label_fine', data=y_f.astype(np.int_), **comp_kwargs)
    with open(os.path.join(cifar_caffe_directory, 'train.txt'), 'w') as f:
        f.write(train_filename + '\n')
    # Test
    with h5py.File(test_filename, 'w') as f:
        f.create_dataset('data', data=Xt, **comp_kwargs)
        f.create_dataset('label_coarse', data=yt_c.astype(np.int_), **comp_kwargs)
        f.create_dataset('label_fine', data=yt_f.astype(np.int_), **comp_kwargs)
    with open(os.path.join(cifar_caffe_directory, 'test.txt'), 'w') as f:
        f.write(test_filename + '\n')
    
    print('Conversion successfully done to "{}".\n'.format(cifar_caffe_directory))
else:
    print("Conversion was already done. Did not convert twice.\n")
